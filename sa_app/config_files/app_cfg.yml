#################
# GLOBAL PARAMS #
#################
seed: &seed 42


###############
# Data params #
###############
dataset_params:  
  # wandb_storage: # If this is defined the data artifacts are downloaded from wandb
  #   wandb_dataset_url: "bdp_grp2/sa-roberta/sentiment-dataset:v1"
  #   src_file_type: "csv"
  #   mapping_file_name: "mapping.txt"
  local_storage: # If wandb_storage is not defined the data artifacts referred from local path configured below
    raw_dataset_file: "C:\\Users\\mini-KRONOS\\OneDrive\\Documents\\Github\\dataset\\training.1600000.processed.noemoticon.csv"
    labels_mapping: "C:\\Users\\mini-KRONOS\\OneDrive\\Documents\\Github\\sentiment-analysis-gke-pipeline\\sa_app\\config_files\\mapping.txt"
  max_length: 128
  batch_size: 32
  preprocessors:
    base_cleaning:
      {}
    lowcase:
      {}
    stem:
      language: 'english'
    lemma:
      model_name: 'en_core_web_sm'
    cardiffnlp_processor:
      {}


###################
# Training params #
###################
training_params:
  base-model-name: "cardiffnlp/twitter-roberta-base"
  train_mode: "fine_tune_base_model"
  debug_size: 3
  tokenizer: 'cardiffnlp/twitter-roberta-base-sentiment-latest'
  learning_rate: 1e-5
  num_epochs: 1

  custom_classification_head:
    input_dim: 768
    num_labels: 2

  optimizer:
    type_: adamW
    lr: 1.e-5
    weight_decay: 0.01

  lr_scheduler:
    type_: 'lin_warmup'
    interval: 'step'
    lr_warmup: 0.1

  trainer:
    max_steps: 10
#    max_epochs: 20
#    accumulate_grad_batches: 1 # use when memory is not sufficient
    gradient_clip_val: 1
    # precision: bf16-mixed
    precision: 16-mixed
    limit_train_batches: 3
    limit_val_batches: 3
    log_every_n_steps: 3
    val_check_interval: 1
    

  wandb_storage:
    name: "sa-roberta"
    artifact_name: "best_model_checkpoint"
    artifact_type: "model"

  logging:
    log_dir: "C:\\Users\\mini-KRONOS\\OneDrive\\Documents\\Github\\logs"

  callbacks:
    dirpath: "C:\\Users\\mini-KRONOS\\OneDrive\\Documents\\Github\\models"
    monitor_var: 'valid_acc_step'
    monitor_var_mode: 'max'
    save_top_k: 1


####################
# Inference params #
####################

inference_params:
  model_dir: "bdp_grp2-org/wandb-registry-model/test:v0"
  default_model_name: "best_model-v4.ckpt"
  base_model_name: "cardiffnlp/twitter-roberta-base-sentiment-latest"
